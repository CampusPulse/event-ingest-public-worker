---
name: "[production] [repo] all stages / all sites"
on:
  schedule:
    cron: "48 6 * * 2" # “At 06:48 on Tuesday.” Github doesnt like stuff at the top of the hour and weekly seems often enough, while also giving RIT people one workday to set up events for the week

jobs:
  repo-worker:
    environment: results-repo
    timeout-minutes: 60
    if: ${{ github.ref == 'refs/heads/main' }}
    env:
      RESULTS_REPO: results-repo
    runs-on: ubuntu-latest
    steps:
      - name: apt-get dependencies
        run: |
          sudo apt-get update
          sudo apt-get install libbz2-dev liblzma-dev libreadline-dev libsqlite3-dev pdftohtml

      - uses: actions/checkout@v2
        with:
          repository: CampusPulse/event-data-ingest
          path: ./event-data-ingest/
          submodules: true

      # - uses: actions/checkout@v2
      #   with:
      #     repository: CAVaccineInventory/event-data-ingest-results
      #     path: ./{{ env.RESULTS_REPO }}/
      #     token: ${{ secrets.WORKER_PAT }}

      - name: get python version
        working-directory: event-data-ingest
        run: |
          python_version=$(cat .python-version)
          echo "python_version=${python_version}" >> $GITHUB_ENV

      - uses: actions/setup-python@v2
        with:
          python-version: ${{ env.python_version }}

      - name: setup from README.md
        run: |
          curl -sSL https://install.python-poetry.org/ | python -
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: load poetry install from cache
        id: cached-poetry-dependencies
        uses: actions/cache@v2
        with:
          path: event-data-ingest/.venv
          key: venv-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}

      - run: poetry install
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        working-directory: event-data-ingest

      - name: run fetch, parse, normalize
        working-directory: event-data-ingest
        run: |
          mkdir ../results
          poetry run event-data-ingest pipeline --stages=fetch,parse,normalize --output-dir ../results --no-fail-on-runner-error

      - name: roll-up results
        working-directory: results
        run: |
          find out -type f -mtime -1 -exec ls -lt {} + | grep "normalized" | awk '{print $NF}' 2> /dev/null |xargs cat > "concatenated_events.parsed.normalized.ndjson"
      
      - name: upload results
        working-directory: results
        run: | 
          curl -X POST "https://api.events.campuspulse.app/v0/import" \
          -u "loader:${{ secrets.API_PASSWORD }}" \
          -F "file=@concatenated_events.parsed.normalized.ndjson"

      # - run: git status
      #   working-directory: '{{ env.RESULTS_REPO }}'
      #   if: ${{ github.ref != 'refs/heads/main' }}

      # - name: push results
      #   working-directory: '{{ env.RESULTS_REPO }}'
      #   if: ${{ github.ref == 'refs/heads/main' }}
      #   run: |
      #     git config user.name "🤖 Vaccinebot"
      #     git config user.email "82560569+Vaccinebot@users.noreply.github.com"
      #     git add -A
      #     timestamp=$(date -u)
      #     git commit -m "Latest data: ${timestamp}" || exit 0
      #     git push
